### From https://medium.com/@hirok4/derivation-of-training-loss-in-diffusion-model-844840352950

1. Introduction
   Diffusion models have a forward process (adding noise step-by-step) and a reverse process (removing noise step-by-step). 
   The model aims to learn the reverse process distribution 
   ğ‘_ğœƒ(ğ‘¥_(0:ğ‘‡)) that matches the forward process distribution ğ‘(ğ‘¥_(0:ğ‘‡))

   The training objective is derived from a variational lower bound on the data log-likelihood.
   The forward and reverse processes are described as follows:

   -a. Forward process: A Markov chain gradually adds Gaussian noise to data according to a variance schedule 
       ğ›½_1, â€¦ ,ğ›½_ğ‘‡
   -b. Reverse process: Defined as a Markov chain with learned Gaussian transitions that tries to invert the forward noising process.

2. Notation:
   -a. ğ‘¥_0 is the original data (e.g., image)
   -b. ğ‘¥_(1:ğ‘‡) are noisy versions of ğ‘¥_0
   -c. ğ‘_ğœƒ(ğ‘¥_(0:ğ‘‡)) is the reverse process distribution (a Markov chain of Gaussians).
   -d. ğ‘(ğ‘¥_(1:ğ‘‡)âˆ£ğ‘¥_0) is the forward noising distribution.

   From the paper, the integral âˆ«ğ‘_ğœƒ(ğ‘¥_(0:ğ‘‡))ğ‘‘ğ‘¥_(1:ğ‘‡)is intractable. 
   A formula transformation is used, likely leveraging the known forward process distributions to handle the complexity of the reverse process integral.

3. Variational Bound on Negative Log Likelihood
   The training objective is based on minimizing the variational upper bound on the negative log-likelihood of the data:
   ğ¸_ğ‘[âˆ’log ğ‘_ğœƒ(ğ‘¥_0)] â‰¤ ğ¸_ğ‘[âˆ’log ğ‘_ğœƒ(ğ‘¥_0)]+ğ·_ğ¾ğ¿(ğ‘(ğ‘¥_(1:ğ‘‡)âˆ£ğ‘¥_0)âˆ¥ğ‘_ğœƒ(ğ‘¥_(1:ğ‘‡)âˆ£ğ‘¥_0))= ğ¿
   Using Jensen's inequality, this can be decomposed into a sum of KL divergences and a final term that relates to the discrete decoder at the end of the chain.

   The upper bound on âˆ’ log ğ‘_ğœƒ(ğ‘¥_0) is given by the variational lower bound. The paper decomposes this bound into terms 
   ğ¿_0,ğ¿_1, â€¦ ,ğ¿_ğ‘‡

   -a. Key steps:
       -1. Write joint distribution as a product of conditional distributions.
       -2. Apply Jensenâ€™s inequality to get the variational bound.
       -3. Decompose terms to isolate KL divergences and a final data term.

4. Forward and Reverse Processes
   -a. Forward process ğ‘(ğ‘¥_ğ‘¡âˆ£ğ‘¥_(ğ‘¡âˆ’1))=ğ‘(ğ‘¥_ğ‘¡; np.root(1âˆ’ğ›½_ğ‘¡)ğ‘¥_(ğ‘¡âˆ’1),ğ›½_ğ‘¡ ğ¼) is fixed and does not depend on ğœƒ
   -b. The approximate posterior:
       ğ‘(ğ‘¥_(ğ‘¡âˆ’1)âˆ£ğ‘¥_ğ‘¡,ğ‘¥_0) = ğ‘(ğ‘¥_(ğ‘¡âˆ’1);ğœ‡^~_ğ‘¡(ğ‘¥_ğ‘¡,ğ‘¥_0),ğ›½^~_ğ‘¡ ğ¼)
      where ğœ‡^~_ğ‘¡ and ğ›½^~_ğ‘¡ are derived from the forward process parameters.

   In the derivation, the paper uses properties of Gaussian distributions and their combinations to simplify terms.

5. Loss Terms
   Define ğ¿ as the sum of several terms ğ¿_0,ğ¿_1, â€¦ ,ğ¿_(ğ‘‡âˆ’1),ğ¿_ğ‘‡
   These correspond to KL divergences and the data term:

   ğ¿=ğ¿_0 + ğ¿_1 + â‹¯ + ğ¿_(ğ‘‡âˆ’1) + ğ¿_ğ‘‡ 
   
   -a. ğ¿_ğ‘‡ is constant w.r.t. ğœƒ and can be ignored during training if ğ›½_ğ‘¡ are fixed constants.
   -b. For ğ¿_(1:ğ‘‡âˆ’1), the paper sets the reverse process covariance to fixed constants ğœ^2_ğ‘¡ I. 
   
   This leads to a simplified form:
   ğ¿_(ğ‘¡âˆ’1) = ğ¸_ğ‘[ğ·_ğ¾ğ¿(ğ‘(ğ‘¥_(ğ‘¡âˆ’1)âˆ£ğ‘¥_ğ‘¡,ğ‘¥_0)âˆ¥ğ‘_ğœƒ(ğ‘¥_(ğ‘¡âˆ’1)âˆ£ğ‘¥_ğ‘¡))]
   
   To minimize this, the model ğ‘_ğœƒ must predict the mean of the posterior ğœ‡^~_ğ‘¡(ğ‘¥_ğ‘¡,ğ‘¥_0)


6. Reparameterization trick: They use a parameterization predicting ğœ– (the added noise) instead of ğœ‡
   Given ğ‘¥_ğ‘¡, the model tries to predict ğœ– such that:
  
   ğœ‡_ğœƒ(ğ‘¥_ğ‘¡,ğ‘¡) = 1/np.root(ğ›¼^Ë‰_ğ‘¡(ğ‘¥_ğ‘¡âˆ’(ğ›½_ğ‘¡/np.root(1âˆ’ğ›¼Ë‰_ğ‘¡))ğœ–_ğœƒ(ğ‘¥_ğ‘¡,ğ‘¡)))
   
   This transformation simplifies training. The network ğœ–_ğœƒ is trained to predict the noise ğœ–

   -a. ğ¿_0 involves a discrete decoding term from a Gaussian into a discrete distribution. 
       The paper approximates it by ignoring certain weights and edge effects.

7. Final Simplified Training Objective
   The final training loss often used in practice simplifies to predicting ğœ– directly. This yields a loss function like:

   ğ¿_simple = ğ¸_(ğ‘¡,ğ‘¥_0,ğœ–)[âˆ¥ğœ–âˆ’ğœ–_ğœƒ(ğ‘¥_ğ‘¡,ğ‘¡)âˆ¥^2]

   where ğ‘¥_ğ‘¡ = np.root(ğ›¼Ë‰ğ‘¡)ğ‘¥_0 + np.root(1âˆ’ğ›¼Ë‰_ğ‘¡)ğœ–
   This simpler loss was found to produce good results empirically, removing weighting terms from the original derived formula.

8. Appendix: Derivation of ğ‘(ğ‘¥_(ğ‘¡âˆ’1)âˆ£ğ‘¥_ğ‘¡,ğ‘¥_0)
   The text shows a derivation for mean and variance of the Gaussian 
   ğ‘(ğ‘¥_(ğ‘¡âˆ’1)âˆ£ğ‘¥_ğ‘¡,ğ‘¥_0):
                    ğ‘(ğ‘¥_(ğ‘¡âˆ’1)âˆ£ğ‘¥_ğ‘¡,ğ‘¥_0)âˆğ‘(ğ‘¥_ğ‘¡âˆ£ğ‘¥_(ğ‘¡âˆ’1),ğ‘¥_0)ğ‘(ğ‘¥_(ğ‘¡âˆ’1)âˆ£ğ‘¥_0)

   Gven:
        ğ‘(ğ‘¥_ğ‘¡âˆ£ğ‘¥_(ğ‘¡âˆ’1))=ğ‘(ğ‘¥_ğ‘¡; np.root(1âˆ’ğ›½_ğ‘¡)ğ‘¥_(ğ‘¡âˆ’1),ğ›½_ğ‘¡ ğ¼)
        ğ‘(ğ‘¥_(ğ‘¡âˆ’1)âˆ£ğ‘¥_0)=ğ‘(ğ‘¥_(ğ‘¡âˆ’1); np.root(ğ›¼Ë‰_(ğ‘¡âˆ’1))ğ‘¥_0,(1âˆ’ğ›¼Ë‰_(ğ‘¡âˆ’1)ğ¼)

   where ğ›¼Ë‰_(ğ‘¡âˆ’1)=âˆ_(ğ‘ =1 to ğ‘¡-1)(1âˆ’ğ›½_ğ‘ )
   The product of these Gaussians results in:

   ğ‘(ğ‘¥_(ğ‘¡âˆ’1)âˆ£ğ‘¥_ğ‘¡,ğ‘¥_0) = ğ‘(ğ‘¥_(ğ‘¡âˆ’1); ğœ‡^~_ğ‘¡(ğ‘¥_ğ‘¡,ğ‘¥_0),ğ›½^~_ğ‘¡ ğ¼)

  They use Gaussian identities for product of distributions, calculating the combined mean and variance from the two input Gaussians.
  The derived mean and variance ğœ‡^~_ğ‘¡,ğ›½^_ğ‘¡ are used in the simplified training objectives.

9. Conclusion
   The text describes how diffusion model training loss is derived from a variational perspective, 
   starting with the log-likelihood bound and decomposing it into KL and data terms. 
   By fixing certain parameters and carefully reparameterizing the model to predict noise ğœ–, a simpler and more effective training loss emerges. 
   Although the paperâ€™s details are intricate, this summary captures the main transformations and justifications behind the final training objective 
   used in diffusion model training.
