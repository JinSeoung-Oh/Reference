### From https://medium.com/correll-lab/flow-matching-for-generative-models-from-scratch-8264bad4e0ba

1. From Diffusion to Flow Matching
   -a. Diffusion models corrupt data by gradually adding Gaussian noise via a forward process ğ‘, then train a network ğ‘_ğœƒ
       to predict and remove that noise, reconstructing the original image.
   -b. Flow matching treats each pixel (or data dimension) as a random variable following a Gaussian. 
       Instead of predicting noise, it learns a time-dependent velocity field ğ‘£_ğœƒ(ğ‘¥,ğ‘¡) that moves particles from a simple
       â€œpriorâ€ (e.g. ğ‘(0,1)) to the target distribution (the clean image) over a unit time interval.
   -c. Because flow matching directly models how samples should flow between distributions, 
       it often requires less training data and can converge faster than diffusion.

2. Images as Random Variables
   -a. Noisy image generation: An 8Ã—8 RGB image ğ‘¥_0 can be turned into a random image by adding ğ‘(0,ğœ^2) noise:
       ğ‘¥_ğ‘¡=ğ‘(ğ‘¥_0)=ğ‘¥_0+ğœ–,ğœ–âˆ¼ğ‘(0,ğœ^2)
   -b. Inverse mapping: A neural network ğ‘_ğœƒ learns to predict how much noise to remove.
   -c. Unified view: All 64 pixels form a 64-dimensional Gaussian. Flow matching instead learns 
                     ğ‘£_ğœƒ that transports samples from ğ‘(0,ğ¼) to the imageâ€™s Gaussian.

3. Transforming Distributions via Velocity Fields
   -a. Single-pixel example:
       -1. Source: samples ğ‘¥_0âˆ¼ğ‘(0,1)
       -2. Target: samples ğ‘¥^~âˆ¼ğ‘(2,0.5)
   -b. A velocity field ğ‘£(ğ‘¥,ğ‘¡) describes how a sample at position ğ‘¥ at time ğ‘¡ should move:
      ğ‘‘_ğ‘¥/ğ‘‘_ğ‘¡=ğ‘£(ğ‘¥,ğ‘¡)
   -c. Integration over ğ‘¡âˆˆ[0,1] via Eulerâ€™s method transforms the entire distribution.
   -d. Sampling pairing trick: Randomly pair ğ‘¥_0âˆ¼ğ‘_0 and ğ‘¥_1âˆ¼ğ‘_1. Connect them with straight lines; 
       averaging over many such pairs reveals the average velocity fieldâ€”no explicit correspondence needed.

4. Code Walk-through
   4.1 Visualization of Source vs. Target
   """
   # Plot histograms of N(0,1) vs. N(2,0.5)
   plt.hist(source_distribution(1000), bins=50, density=True, alpha=0.6, label='N(0,1)')
   plt.hist(torch.normal(2.0, 0.5, (1000, 1)), bins=50, density=True, alpha=0.6, label='N(2,0.5)')
   """
   Purpose: Shows how noisy samples (orange) compare to target samples (green), motivating the need for a transporting velocity field.

   4.2 Defining the Velocity-Field Model
   """
   class VelocityField(nn.Module):
       def __init__(self, input_dim=1, hidden_dim=128):
           super().__init__()
           self.input_layer = nn.Linear(input_dim + 1, hidden_dim)
           # ... two more hidden layers with LayerNorm+ReLU and residuals ...
           self.output_layer = nn.Linear(hidden_dim, input_dim)

       def forward(self, x, t):
           xt = torch.cat([x, t], dim=-1)
           h = self.relu(self.norm1(self.input_layer(xt)))
           # residual blocks ...
           return self.output_layer(h)
   """
   -a. Inputs: current sample ğ‘¥ and time ğ‘¡
   -b. Architecture:
       -1. Input layer projects (ğ‘¥,ğ‘¡) into a 128-dim latent space.
       -2. Two residual hidden layers (with LayerNorm + ReLU).
       -3. Output layer returns a velocity scalar.

   4.3 Training Loop (Euler Integration)
   """
   for epoch in range(epochs+1):
       x = source_distribution(n_samples).to(device)
       # Simulate flow
       for t in time_steps[:-1]:
           v = model(x, t * torch.ones(...))
           x = x + v * dt   # Euler step
       loss = torch.mean((x - target_samples)**2)
       loss.backward(); optimizer.step()
   """
   Goal: minimize mean-squared error between the final transported samples and true target samples.
   Observation: Loss drops from ~4.44 to ~0.60 over 30 epochs.

5. Improving with Maximum Mean Discrepancy (MMD)
   -a. Issue: Simple MSE between random pairs can collapse variances.
   -b. MMD offers a non-parametric measure between distributions based on a kernel ğ‘˜(ğ‘¥,ğ‘¦)=exp(âˆ’âˆ¥ğ‘¥âˆ’ğ‘¦âˆ¥^2 / (2ğœ^2))
   -c. Implementation:
   """
   def compute_mmd(x, y, sigma=1.0):
       # pairwise distance matrices xx, yy, xy
       kernel_xx = torch.exp(-xx / (2*sigma**2))
       ...
       mmd = xx.mean() + yy.mean() - 2*xy.mean()
       return mmd
   # then simply:
   loss = compute_mmd(x, target_samples)
   Result: Loss plummets to ~0.0003 by epoch 80, preserving correct target variance.
   """

6. Generating and Visualizing Results
   -a. Sample generation:
   """
   def generate_samples(model, n_steps=50):
       x = source_distribution(n_samples)
       for t in torch.linspace(0,1,n_steps)[:-1]:
           v = model(x, t*ones)
           x = x + v * dt
       return x
   """
   -a. Comparison plot overlays:
       -1. Source histogram (blue)
       -2. Generated histogram (green)
       -3. True target PDF (red curve)

7. Extending to Complex Distributions
   -a. By swapping in any desired target samplerâ€”e.g., a Gaussian mixture
   """
   target_samples = torch.cat([
       torch.normal(2.0,0.5,(n//2,1)),
       torch.normal(-3.0,0.5,(n//2,1))
   ])
   """
   the same training loop learns to map ğ‘(0,1) into a bimodal distribution.

8. Conclusion
   -a. Flow matching leverages an ODE-based viewpoint (Continuous Normalizing Flows) to transport simple priors into 
       complex data distributions via a learned velocity field.
   -b. Advantages over diffusion include faster convergence, fewer samples, and no need for U-Net architectures, 
       while still supporting conditioning (text or image embeddings).
   -c. For deeper dives, the original paper (â€œFlow Matching for Generative Modelingâ€) and accompanying YouTube summary are recommended.

9. Appendix: Velocity-Field Visualization
   -a. Linear trajectories plotted by sampling random pairings and drawing straight-line paths over time.
   -b. Estimated velocity field ğ‘£(ğ‘¥,ğ‘¡) obtained by binning interpolated samples and averaging their true displacements,
       then plotted across ğ‘¥ for several ğ‘¡ values.
   -c. Code relies on NumPy and Matplotlib and mirrors the principles shown above to illustrate how the learned field evolves 
       in grayscale over time.

